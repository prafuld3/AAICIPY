from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import roc_auc_score
import math
import scikitplot.metrics as skplt 
import pandas as pd

y=filtered_data['Score'][:5000]
x=pd.read_pickle('preprocess_reviews')[:5000]

x_tr, x_cv, y_tr, y_cv = train_test_split(x,y,test_size=0.2)
x_train, x_test, y_train, y_test = train_test_split(x_tr, y_tr, test_size=0.2)

bow=CountVectorizer()
x_train = bow.fit_transform(x_train)
x_test = bow.transform(x_test)
x_cv = bow.transform(x_cv)

auc_train_list_l1 = []
auc_train_list_l2 = []
auc_list_l1 = []
auc_list_l2 = []
auc_list = []
list_penalty = []

c=[10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 1, 10**1, 10**2, 10**3, 10**4, 10**5]
c_1 = [math.log(i) for i in c]
for i in c:  
        model1 = SGDClassifier(loss='hinge', alpha=i, penalty='l1')
        model2 = SGDClassifier(loss='hinge', alpha=i, penalty='l2')
        clf_1 = CalibratedClassifierCV(base_estimator=model1, method='isotonic')
        clf_2 = CalibratedClassifierCV(base_estimator=model2, method='isotonic')
        clf_1.fit(x_train, y_train)
        clf_2.fit(x_train, y_train)
        pred_train_1 = clf_1.predict_proba(x_train)[:,1]
        pred_train_2 = clf_2.predict_proba(x_train)[:,1]
        pred_1 = clf_1.predict_proba(x_cv)[:,1]
        pred_2 = clf_2.predict_proba(x_cv)[:,1]
        auc_train_1=roc_auc_score(y_train, pred_train_1)
        auc_train_2=roc_auc_score(y_train, pred_train_2)        
        auc_1=roc_auc_score(y_cv, pred_1)
        auc_2=roc_auc_score(y_cv, pred_2)
        auc_train_list_l1.append(auc_train_1)
        auc_train_list_l2.append(auc_train_2)
        auc_list_l1.append(auc_1)
        auc_list_l2.append(auc_2)
        auc_max = max(auc_1, auc_2)
        if auc_max==auc_1:
            p='L1'
        else:
            p='L2'
            
        auc_list.append(auc_max)
        list_penalty.append(p)
        
        #print('Auc {x1} & Auc {x2}, index {k}'.format(x1=auc_1, x2=auc_2, k=i))
        #print('max auc is {c1} index {k}'.format(c1=auc_max, k=i))
    
#print(auc_list)
#print(list_penalty)

max_auc=max(auc_list)
index_max_auc=auc_list.index(max_auc)


fig=plt.figure(figsize=(9,7))
plt.plot(c_1, auc_list_l1, label='L1 Reg_cv');
plt.plot(c_1, auc_list_l2, label='L2 Reg_cv');
plt.plot(c_1, auc_train_list_l1, label='L1 Reg_Train');
plt.plot(c_1, auc_train_list_l2, label='L2 Reg_Train');
plt.xlabel('Alpha');
plt.ylabel('AUC');
plt.title('AUC of Train & CV wrt Alpha')

plt.legend()
plt.show();

print('we are getting max AUC of {x} for alpha = {x1} & {x2} Regularization'.format(x=max_auc, x1=c[index_max_auc], x2=list_penalty[index_max_auc]))

print("Now let's find AUC of test data for alpha = {x} on {x1} Regularization".format(x=c[index_max_auc], x1=list_penalty[index_max_auc]))
print('\n')
print('•'*18, 'Finding Accuracy', '•'*18)

model_test = SGDClassifier(loss='hinge', alpha=c[index_max_auc], penalty=list_penalty[index_max_auc])
clf_test = CalibratedClassifierCV(base_estimator=model1, method='isotonic')
clf_test.fit(x_train, y_train)
pred_test = clf_test.predict_proba(x_test)[:,1]
y_pred_test = clf_test.predict(x_test)
auc_test = roc_auc_score(y_test, pred_test)
print('\n')
print('we are getting AUC of {x} on test data for alpha = {x2} on {x1} Regularization'.format(x=auc_test, x2=c[index_max_auc], x1=list_penalty[index_max_auc]))

# plotting ROC curve on test data
y_pred_train_1 = clf_test.predict_proba(x_train)[:,1]
tpr_train, fpr_train, threshold = roc_curve(y_train, y_pred_train_1)
tpr_test, fpr_test, threshold = roc_curve(y_test, pred_test)

plt.plot([0,1], [0,1], linestyle='--')
plt.plot(fpr_train, tpr_train, marker='.', label='Train_Roc')
plt.plot(fpr_test, tpr_test, marker='.', label='Test_Roc')
plt.xlabel('False Positive rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

print('Confusion matrix')

skplt.plot_confusion_matrix(y_test, y_pred_test);


# Feature Importance

#print(model_test.coef_)
      
#dict_feature = dict(zip(bow.get_feature_names(), model_test.coef_[0]))


#print(dict_feature)

#print(dict_feature)

#print(x_train.get_feature_names())

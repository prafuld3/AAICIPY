from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve
import scikitplot.metrics as skplt
from sklearn.metrics import auc

y=filtered_data['Score'][:25000]
df_2=pd.read_pickle('preprocess_reviews')
x=df_2[:25000]

x_tr, x_cv, y_tr, y_cv = train_test_split(x, y, test_size=0.2)
x_train, x_test, y_train, y_test = train_test_split(x_tr, y_tr, test_size=0.2)

count_vect=TfidfVectorizer(ngram_range=(1,2), min_df=10, max_features=500)

#print(len(x_train), len(x_test), len(x_cv))

x_train=count_vect.fit_transform(x_train)
x_train=x_train.toarray()
x_cv=count_vect.transform(x_cv)
x_cv=x_cv.toarray()
x_test=count_vect.transform(x_test)
x_test=x_test.toarray()
cv_acc_list = []
train_acc_list=[]
i_value=[]
for i in range(1,45,2):
    neigh=KNeighborsClassifier(n_neighbors=i, algorithm='kd_tree', n_jobs=-1)
    neigh.fit(x_train, y_train)
    pred_train=neigh.predict_proba(x_train)[:,1]
    pred_cv=neigh.predict_proba(x_cv)[:,1]
    kn=roc_auc_score(y_cv, pred_cv)
    tn=roc_auc_score(y_train, pred_train)
    cv_acc_list.append(kn)
    train_acc_list.append(tn)
    i_value.append(i)
    #print('for k={l} accuracy is {j}'.format(l=i, j=kn))
    
# ploting graph of accuracy wrt k
plt.title('Accuracy of train and CV wrt K')
plt.plot(i_value, cv_acc_list, label='cv_data')
plt.plot(i_value, train_acc_list, label='Train_data')
plt.legend()
plt.xlabel('K value')
plt.ylabel('Accuracy')
plt.show()

print('we are getting maximum accuracy of {x} on k={y} for cv data'.format(x=max(cv_acc_list), y=i_value[cv_acc_list.index(max(cv_acc_list))]))
print("now let's find accuracy on test data for k={x}".format(x=i_value[cv_acc_list.index(max(cv_acc_list))]))

# finding auc of test data.
neighbor=KNeighborsClassifier(n_neighbors=i_value[cv_acc_list.index(max(cv_acc_list))], algorithm='kd_tree', n_jobs=-1)
neighbor.fit(x_train, y_train)
pred_test=neighbor.predict_proba(x_test)[:,1]
pred_train_1=neighbor.predict_proba(x_train)[:,1]
pred_test_1=neighbor.predict(x_test)
auc_test = roc_auc_score(y_test, pred_test)
#print('-'*20, 'finding accuracy', '-'*20)
#print('we got auc of {x} by k={y} on test data'.format(x=auc_test, y=i_value[cv_acc_list.index(max(cv_acc_list))]))

#kd_tree_tfidf_k = i_value[cv_acc_list.index(max(cv_acc_list))]


# plotting Roc curve of test data
#https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/

fpr_test, tpr_test, threshold = roc_curve(y_test, pred_test)
fpr_train, tpr_train, threshold = roc_curve(y_train, pred_train_1)
plt.plot(fpr_train, tpr_train, marker='.', label='Train_AUC='+str(auc(fpr_train, tpr_train)))
plt.plot([0,1], [0,1], linestyle='--')
plt.plot(fpr, tpr, marker='.', label='Test_AUC='+str(auc(fpr_test, tpr_test)))
plt.title('ROC curve')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend()
plt.show()

kd_tree_tfidf_auc=auc(fpr_test, tpr_test)

# confusion matrics

skplt.plot_confusion_matrix(y_test, pred_test_1);

